# Mastering Transformers (in PyTorch)

This repo contains my work on the book [Mastering Transformers](https://www.packtpub.com/product/mastering-transformers/9781801077651 ).

The original repo from the authors can be found [here](https://github.com/PacktPublishing/Mastering-Transformers).

All Tensorflow code has been ported to Pytorch and use the PyTorch Lightning Library. Some of the steps have also been annotated.

Use the following links to open them directly in colab.

[Chapter 1](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch1.ipynb)

[Chapter 2](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch2.ipynb)

[Chapter 3](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch3.ipynb)

[Chapter 4](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch4.ipynb)

[Chapter 5](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch5.ipynb)

[Chapter 6](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch6.ipynb)

[Chapter 7](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch7.ipynb)

[Chapter 8](https://colab.research.google.com/github/mmg10/MastTrans/blob/main/Ch8.ipynb)

# Notes

Install the following libraries
- gensim
- nltk
- matplotlib
- transformers
- datasets
- torch & torchvision
- pytorch_lightning
- torchmetrics
- tableprint



## Chapter 5

This notebook will compute loss and accuracy using the Hugging Face's models (if the labels are provided) as well as using Pytorch. Use anyone of them.
